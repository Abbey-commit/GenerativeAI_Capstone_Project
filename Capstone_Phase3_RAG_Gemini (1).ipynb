{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef7d1c5",
   "metadata": {},
   "source": [
    "# üìò Phase 3: Retrieval-Augmented Generation (RAG) with Gemini 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c2054",
   "metadata": {},
   "source": [
    "\n",
    "In this phase, we combine semantic retrieval using FAISS with **Gemini 2.0** to generate grounded, high-quality responses to questions on drug targets for depression, psychosis, and anxiety.\n",
    "\n",
    "We simulate a RAG pipeline that:\n",
    "1. Accepts a user query.\n",
    "2. Retrieves top-k relevant text chunks from the FAISS index.\n",
    "3. Constructs a prompt for Gemini 2.0 including retrieved context.\n",
    "4. Generates an answer grounded in the retrieved PubMed knowledge.\n",
    "\n",
    "> **Note**: We simulate Gemini 2.0 here using the `google.generativeai` package.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a49e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q google-generativeai faiss-cpu sentence-transformers\n",
    "import google.generativeai as genai\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "# Load model and index again (if needed in runtime)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Gemini configuration\n",
    "genai.configure(api_key=\"your_google_api_key\")  # Replace with your Gemini API Key\n",
    "gemini = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e10df",
   "metadata": {},
   "source": [
    "### üîÑ Load Existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d28cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your existing index (in real-world, index should be stored/persisted)\n",
    "# Recreate index here for simplicity\n",
    "text_chunks = [...]  # Replace this with actual list of text chunks from Phase 2\n",
    "embeddings = model.encode(text_chunks).astype(\"float32\")\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c43990",
   "metadata": {},
   "source": [
    "### üîç Define Retrieval + Gemini 2.0 RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7886528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_relevant_chunks(query, top_k=5):\n",
    "    query_vector = model.encode([query]).astype(\"float32\")\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    return [text_chunks[i] for i in indices[0]]\n",
    "\n",
    "def generate_rag_response(query):\n",
    "    context_chunks = retrieve_relevant_chunks(query)\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = f\"You are a biomedical research assistant helping identify drug targets.\\n\\nContext:\\n{context}\\n\\nUser Question: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    response = gemini.generate_content(prompt)\n",
    "    return response.text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2531c742",
   "metadata": {},
   "source": [
    "### üß™ Test: Drug Targets for Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72606f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"What are the latest drug targets for treating depression?\"\n",
    "response = generate_rag_response(query)\n",
    "print(\"ü§ñ Gemini 2.0 Response:\\n\")\n",
    "print(response)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
